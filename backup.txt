%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% How to use writeLaTeX: 
%
% You edit the source code here on the left, and the preview on the
% right shows you the result within a few seconds.
%
% Bookmark this page and share the URL with your co-authors. They can
% edit at the same time!
%
% You can upload figures, bibliographies, custom classes and
% styles using the files menu.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}

\usepackage[brazil]{babel} 
\usepackage[utf8]{inputenc}
\usepackage{dirtytalk}

\sloppy

% \title{De Florestas Aleatórias à Baías Ingênuas: Aplicação de Machine Learning no Processamento de Dados de Necropsias do PMP-BS }

\title{Aplicação de Machine Learning no Processamento de Dados de Necrópsias do PMP-BS}

\author{Felipe S. Dalcin\inst{1}, Anita Maria da Rocha Fernandes\inst{1}, Rodrigo Sant'Ana\inst{1}}

\address{Curso de Pós-Graduação em Big Data - Universidade do Vale do Itajaí (UNIVALI)\\
  Campus Kobrasol - São José, SC SC - Brasil
  \email{felipe.dalcin@edu.univali.br, \{anita.fernandes, rsantana\}@univali.br}
}

\begin{document} 

\maketitle

\begin{abstract}

This article presents an analysis of expert reports of animals collected by the Bacia de Santos Beach Monitoring Project (PMP-BS). In order to identify if there was any interaction due to human interference. This indicator is important since it can assist in determining the cause of death of the animal. The study uses concepts of artificial intelligence and machine learning algorithms to find patterns and identify if the animal has had contact with fishing nets, for example. Finally, it was possible to obtain a very satisfactory model in a first analysis, achieving 90.79\% accuracy in the classification of interactions.

\end{abstract}
     
\begin{resumo} 

Este artigo apresenta uma análise de laudos periciais de animais coletados pelo Projeto de Monitoramento de Praias da Bacia de Santos (PMP-BS), com o propósito de identificar se houve alguma interação por interferência dos seres humanos (interações antrópicas). Este indicativo é importante, uma vez que pode auxiliar na determinação da causa da morte do animal. O estudo se utiliza de conceitos de inteligência artifical e algoritmos de aprendizagem de máquina (Machine Learning) para identificar padrões e determinar se o animal teve contato com redes de pesca, por exemplo. Por fim, foi possível obter um modelo bastante satisfatório em uma primeira análise, atingindo 90.79\% de acurácia na classificação das interações.

\end{resumo}

\section{Introdução}

A população mundial está concentrada, em sua maioria, em regiões costeiras. As características destas regiões proporcionam um alto desenvolvimento econômico por meio de indústrias, ocupação portuária, exploração petrolífera, pesca, turismo, dentre outros \cite{mma:zcmu}. No entanto, a alta concentração demográfica e o modelo de produção acelerado trazem, também, impactos negativos, principalmente ao meio ambiente \cite{mma:zcmu, mma:pngc}.

Proporcional ao crescimento socioeconômico tem-se o aumento da poluição de corpos d'água e ocupação desordenada do solo. A fauna destas regiões é bastante sensível às alterações no ambiente, sofrendo com problemas de derramamento de óleo, contaminação por metais pesados, poluição e destruição de áreas de reprodução \cite{mma:zcmu,scherer:litoral}.

A poluição das regiões costeiras e sua fauna é alvo de crescente preocupação mundial. No Brasil, para a obtenção de licenciamento ambiental, o IBAMA exige a aplicação de programas que visem avaliar e controlar os impactos causados pela exploração de recursos naturais \cite{mma:pngc, petrobras:pmp}. 

Neste contexto, o Projeto de Monitoramento de Praias da Bacia de Santos (PMP-BS) é uma atividade que está relacionada ao processo de licenciamento da PETROBRAS. Este projeto tem como objetivo, por meio do monitoramento das praias e atendimento veterinário, avaliar possíveis interferências das atividades de produção e escoamento de petróleo e gás natural sobre animais tetrápodes marinhos \cite{univali:pmp,petrobras:anual1}.

Todos os animais vivos encontrados durante o monitoramento são avaliados e recebem atendimento veterinário caso necessário. Após o tratamento, são reavaliados e marcados antes da liberação, permitindo o acompanhamento em caso de reaparecimento. Para os animais encontrados mortos ou que venham a morrer durante o processo de reabilitação, são realizadas necrópsias para tentar identificar o motivo do óbito e se houve interação antrópica - interação causada por interferência humana \cite{univali:pmp, petrobras:anual1}.

No entanto, uma das grandes dificuldades do processo são as condições de coleta dos animais, uma vez que em alguns casos o estado de decomposição e/ou a predação dos mesmos impede que se consiga obter dados confiáveis. Em espécies muito comuns, dá-se prioridade para os indivíduos em melhor estado de conservação \cite{petrobras:pmp, petrobras:anual1}.

Identificar interações antrópicas com os indivíduos é de grande importância, uma vez que pode auxiliar na compreensão da causa da morte do animal. É possível, também, conhecer quais atividades estão sendo desenvolvidas em uma determinada área e se estas atividades estão, de alguma forma, prejudicando a fauna local.

Neste contexto, o objetivo deste artigo é determinar se houve algum tipo de interferência humana com os indivíduos coletados. Para este fim, serão aplicados conceitos de Inteligência Artificial e Aprendizagem de Máquina para classificar as interações com base nos laudos periciais. Os dados utilizados para a pesquisa foram obtidos pelo PMP-BS e compreendem um período de agosto de 2015 a outubro de 2019.

\section{Trabalhos Relacionados}

No meio acadêmico, não é comum a utilização de inteligência artificial e modelos de predição com objetivos semelhantes ao desta pesquisa. Pode-se citar, no entanto, algumas pesquisas que visam identificar impactos de atividades humanas na área ambiental.

\subsection{Avaliação de Incêndios Causados por Indução Humana}

Esta pesquisa apresenta uma visão sobre a utilização de \textit{Machine Learning (ML)} na avaliação da ocorrência de incêndios. São comparados alguns algoritmos no contexto de previsão do risco de incêndios e, especificamente, na avaliação de incêndios induzidos por humanos. Três modelos são avaliados em relação a modelos estatísticos tradicionais, como \textit{Logistic Regression (LR)}, sendo eles: (i) \textit{Random Forest (RF)}; (ii) \textit{Boosting Regression Trees (BRT)}; e (iii) \textit{Support Vector Machine (SVM)} \cite{rodrigues:wildfire}.

Segundo os autores, os modelos de ML contribuíram para o aumento da performance em relação aos modelos tradicionais, sugerindo que sejam mais apropriados no contexto da pesquisa. Ainda, o modelo RF foi o mais adequado pois, além de obter melhor acurácia, possui uma parametrização mais simples e precisa de menos variáveis preditoras para alcançar bons resultados \cite{rodrigues:wildfire}.

\subsection{Mapeamento de Plantas Ameaçadas de Extinção}

Modelos de ML são aplicados, também, para mapear a distribuição de  de espécies de plantas raras e ameaçadas de extinção. O estudo busca compreender a amplitudde dos potenciais \textit{habitats} das espécies estudadas em comparação com os \textit{habitats} atualmente observados \cite{pouteau:endangered}.

Os resultados, mostram que a área de ocorrência atual destas plantas é consideravelmente menor aos resultados obtidos na pesquisa. Os autores consideram, como hipótese, o impacto de ações antrópicas que ocorreram ao longo dos anos. A pesquisa conclui que é necessário estabelecer estratégias para garantir a conservação destas espécies e prevenir o encolhimento das áreas de ocorrência \cite{pouteau:endangered}.

\section{Desenvolvimento}

Os dados utilizados neste artigo foram coletados pelo PMP-BS. A base original contém um total de 24.875 registros de indivíduos necropsiados, compreendendo o período de agosto de 2015 a outubro de 2019. Estes registros são apresentados através de 111 variáveis que descrevem o processo desde o momento da coleta até o descarte da carcaça.

Todo o desenvolvimento foi executado utilizando a linguagem R e pacotes que auxiliam na limpeza e apresentação de dados, bem como pacotes para aplicação de algoritmos de aprendizagem de máquina. Nesta seção são detalhados alguns destes processos.

\subsection{Análise e Limpeza dos Registros}

A compreensão dos dados contidos na base é bastante importante para a construção de bons modelos. Esta seção destina-se a apresentar o processo de conhecimento e limpeza dos dados, desde o processo de descarte de variáveis não necessárias ao modelo, até a extração de informações de variáveis complexas. 

\subsubsection{Primeira Análise}

Após uma primeira análise das informações, 41 variáveis foram descartadas, uma vez que se referem a identificadores do PMP-BS que não apresentam influência no processo de classificação dos dados.

Do total de registros, 17.633 são o alvo desta pesquisa por não apresentarem informação sobre interação com o ser humano, não sendo possível utilizá-los para treinar os modelos. Os demais registros foram classificados em dois grupos, sendo: (i) Indivíduos que apresentaram UMA interação antrópica; e (ii) Indivíduos que apresentaram MÚLTIPLAS interações antrópicas.

Para este primeiro estudo, foram considerados apenas registros do primeiro grupo, o que resultou em um total de 6.178 registros a serem utilizados nos modelos classificadores.

\subsubsection{Variáveis com Múltiplas Informações}

Algumas variáveis da base apresentavam múltiplas informações, de forma que foi necessário separar estas informações em \textit{n} outras variáveis, sendo:

A variável \say{interacoes\_antropicas} apresentava informações de tipo e nível da interação e foi dividida em \say{interacao\_tipo} e \say{interacao\_nivel}.

As variáveis \say{cavidades\_corporeas}, \say{tecido\_cutaneo\_e\_subcutaneo},  \say{sistema\_musculo\_esqueletico}, \say{sistema\_respiratorio}, \say{sistema\_cardiovascular}, \say{aparato\_digestorio}, \say{sistema\_urinario}, \say{sistema\_reprodutivo}, \say{sistema\_linfo\_hematopoietico}, \say{sistema\_endocrino}, \say{orgaos\_dos\_sentidos} e \say{sistema\_nervoso\_central} apresentavam três informações distintas, sendo: (i) \textit{Status}, indicando se houve alteração; (ii) Motivo, descrevendo o porquê de o órgão não ter sido examinado; e (iii) Análise, descrevendo possíveis alterações no órgão. Estas foram divididas conforme tabela \ref{tab:spread_variaveis}.

\begin{table}[ht]
\centering
\caption{Divisão das variáveis referentes aos órgãos do indivíduo.}
\label{tab:spread_variaveis}
\includegraphics[width=.8\textwidth]{tabela_spread_variaveis.png}
\end{table}

\subsubsection{Variáveis Textuais}

Como a maioria dos dados são apresentados de forma textual, foram necessários alguns tratamentos para eliminar possíveis inconsistências entre registros. Todos os valores foram convertidos para letras minúsculas, removendo acentuações e pontuações.

Após a aplicação dos tratamentos ainda foi realizada a conversão das colunas identificadas como \textit{chr} para o tipo \textit{factor}, assim permitindo a verificação da correlação entre as variáveis a serem utilizadas no modelo.

\subsubsection{Variáveis com Dados Vazios ou Nulos}

Após estes tratamentos, foi observado que algumas variáveis apresentavam textos vazios. Sendo que, para as variáveis \say{diagnostico\_presuntivo\_lesao\_principal\_orgao}, \say{diagnostico\_presuntivo\_lesao\_principal\_causa}, \say{diagnostico\_primario\_lesao\_principal\_orgao}, \say{diagnostico\_primario\_lesao\_principal\_causa} e \say{presenca\_de\_residuos\_solidos} os dados vazios foram alterados para \say{indeterminado}, permitindo analisar alguns padrões importantes.  As demais variáveis foram convertidas para \textit{NA}.

Verificou-se, conforme demonstrado na figura \ref{fig:pre_missing_data}, o percentual de ausência de dados para cada variável que poderia ser utilizada no modelo. Consideram-se variáveis boas aquelas que possuem um baixo percentual de dados ausentes (até 5\%). As demais variáveis foram descartadas, uma vez que o percentual de ausência é superior a 40\%, comprometendo, assim, as análises dos modelos.

\begin{figure}[ht]
\centering
\includegraphics[width=.8\textwidth]{dados_faltantes_pre_limpeza.png}
\caption{Percentual de ausência de dados por variável.}
\label{fig:pre_missing_data}
\end{figure}

\subsection{Pré Processamento}

Após o processo de limpeza dos dados foi verificada a correlação entre as variáveis, buscando compreender como as variáveis estão relacionadas com a variável dependente (interação antrópica). Foi realizada, também, a separação das bases de treino e teste, garantindo que o modelo seja avaliado com valores de entrada diferentes dos utilizados no momento de treinamento do mesmo \cite{lantz:mlinR}.

\subsubsection{Correlação}

A correlação entre duas variáveis refere-se ao Coeficiente de Correlação de Pearson e é um indicador que mede relação entre duas variáveis. A medida compreende um intervalo entre -1 e +1 sendo que, quanto mais próximo dos extremos, mais forte é a relação e, quanto mais próximo de zero, mais fraca é a relação \cite{lantz:mlinR}.

Correlações negativamente fortes implicam que, ao aumentar o valor de uma variável, sua correlacionada terá seu valor diminuído. Já as correlações positivamente fortes implicam que, ao aumentar o valor de uma variável, sua correlacionada também aumentará \cite{lantz:mlinR, aggarwal:dcaa}.

Na figura \ref{fig:correlation} é possível observar a correlação entre as variáveis após o processo de limpeza da base. Pode-se perceber que existem algumas correlações relativamente fortes, principalmente nas variáveis referentes aos órgãos do animal. Nota-se, também, uma relação bastante forte entre os diagnósticos presuntivos e primários.

\begin{figure}[ht]
\centering
\includegraphics[width=.8\textwidth]{correlacao_dados_sem_na.png}
\caption{Correlação entre as variáveis.}
\label{fig:correlation}
\end{figure}

\subsubsection{Separação dos Dados}

Por fim, para gerar os modelos classificadores, as variáveis utilizadas no modelo foram normalizadas utilizando a padronização \textit{z-score} com o objetivo de garantir que valores distoantes de cada variável tenham seu impacto considerado \cite{lantz:mlinR}.

Após a padronização dos valores, a base final foi divida em duas partes: (i) Base de treino, utilizada para construir e treinar os modelos; e (ii) Base de testes, a qual foi utilizada para medir a acurácia de cada modelo obtido. Esta divisão foi realizada a partir da seleção aleatória dos registros em uma proporção de 70\% do total de registros para a base de treino e 30\% para a base de teste.
    
\subsection{Processamento}

Para gerar os modelos de aprendizagem de máquina utilizou-se o pacote \textit{caret} da linguagem R, o qual fornece diversas funcionalidades desde o momento de divisão dos dados até estimativa de importância de cada variável para o modelo \cite{caret:r}.

Todos os algoritmos testados nesta pesquisa foram treinados utilizando o método \textit{cross-validation} (CV), o qual consiste em dividir os dados de treino em \textit{n} conjuntos menores. Um dos \textit{n} conjuntos é utilizado para treinar o modelo enquanto os outros \textit{n-1} conjuntos são utilizados para teste \cite{lantz:mlinR}. 

O CV foi parametrizado para repetir este processo dez vezes utilizando 10 subconjuntos em cada processo.

\subsubsection{Naive Bayes}

\textit{Naive Bayes (NB)} é um algoritmo de classificação que faz uso do teorema de Bayes. É um algoritmo simples, mas que se tornou bastante utilizado, principalmente na classificação de textos. Possui este nome pelo fato de realizar suposições \say{ingênuas} sobre os dados. Este algoritmo assume que todas as variáveis da base são igualmente importantes e independentes, por exemplo \cite{lantz:mlinR, aggarwal:dcaa}.

Apesar de ser simples e funcionar bem com dados distoantes, ainda depende de suposições fracas em relação às variáveis e não é ideal em bases com um número muito grande de variáveis numéricas \cite{lantz:mlinR}.

O pacote \textit{caret} fornece o método \textit{naive\_bayes} que aceita três parâmetros de ajuste do modelo, sendo: (i) \textit{laplace}, utilizado para aplicar a correção de Laplace, a qual serve para evitar que a probabilidade de um evento acontecer seja nula \cite{lantz:mlinR, caret:r}; (ii) \textit{usekernel}, permite alterar o modelo de estimativa de densidade para variáveis contínuas; e (iii) \textit{adjust}, permite ajustar a flexibilidade da estimativa de densidade do kernel.

A parametrização foi realizada com a opção \textit{usekernel} sempre \textit{TRUE} para garantir uma melhor estimativa dos dados numéricos. Foram testadas todas as combinações entre dois valores de \textit{laplace} (0 e 1) e três valores de \textit{adjust} (1, 2 e 3), resultando em valores ótimos para \textit{laplace = 0} e \textit{adjust = 2}.

\subsubsection{k-Nearest Neighbor}

O algoritmo de classificação \textit{k-Nearest Neighbor (kNN)} busca por \textit{k} registros similares ao que está sendo testado e assume a classe de maior ocorrência dentro dos similares encontrados. Para selecionar os similares o algoritmo calcula a distância entre os registros comparando os valores de cada variável analisada \cite{lantz:mlinR}.

A escolha do valor de \textit{k} é importante para garantir que o modelo não vá sofrer com variações causadas por ruídos nos dados nem ignorar padrões importantes. Na bibliografia é recomendada a utilização de valores entre 3 e 10. Outra prática comum, é utilizar um valor que seja a raiz quadrada do total de registros de treino \cite{lantz:mlinR, bonaccorso:mla}.

O pacote \textit{caret} fornece o método \textit{knn} que aceita como parâmetro apenas o valor de \textit{k}. Para este modelo, foram testados dez valores diferentes para \textit{k}, sendo: 5, 7, 9, 11, 13, 15, 17, 18, 21, 23, obtendo o modelo ótimo com a parametrização de \textit{k = 11}. É interessante observar que o aumento do número de vizinhos não contribuiu para a melhora da performance do modelo.

\subsubsection{Decision Tree}

Algoritmos de \textit{Decision Tree (DT)} utilizam um modelo semelhante a uma árvore, onde as ramificações representam observações ou decisões tomadas para chegar a uma conclusão/objetivo (extremidades ou folhas) \cite{lantz:mlinR, aggarwal:dcaa}.

No \textit{caret} é possível escolher entre diversas implementações de algoritmos de árvores. Dentre as opções adequadas, optou-se por utilizar um dos modelos mais conceituados, o qual foi desenvolvido pelo cientista da computação J. Ross Quinlan, denominado C5.0 \cite{lantz:mlinR, caret:r}.

A implementação fornecida pelo pacote \textit{caret} oferece a possibilidade de customizar três parâmetros, sendo: (i) \textit{trials}, indica o máximo de árvores paralelas utilizadas para selecionar a melhor classificação; (ii) \textit{model}, indica se o modelo deve utilizar árvore ou decompor a estrutura para um conjunto de regras; e (iii) \textit{winnow}, utilizado para indicar se o modelo deve pré-selecionar as variáveis de maior impacto \cite{caret:r, cran:r}. 

Para a parametrização  do modelo nesta pesquisa utilizaram-se: valores de 1 a 15 para \textit{trials}, \textit{\say{rules}} ou \textit{\say{tree}} para \textit{model} e \textit{TRUE} ou \textit{FALSE} para \textit{winnow}.  Ressalta-se que todas as combinações possíveis destes valores foram executadas e testadas. 

Observou-se que a pré-seleção variáveis de maior impacto teve consequência negativa na performance do modelo, uma vez que seus resultados foram inferiores em comparação aos resultados sem pré-seleção. Como há um conjunto considerável de variáveis, é possível que o processo tenha desconsiderado pequenas nuances, causando um efeito indesejado no resultado final. Ainda, considerando as parametrizações testadas, o modelo ótimo foi obtido com a combinação de \textit{model = \say{rules}}, \textit{trials = 15} e \textit{winnow = FALSE}.

\subsubsection{Random Forest}

\textit{Random Forest (RF)} é um método baseado em conjuntos de DT e foi definido por Leo Breiman e Adele Cutler. Este modelo trabalha com uma seleção aleatória de variáveis para diversificar os modelos de DT. O algoritmo gera um conjunto de árvores de decisão e combina suas predições, resultando em um modelo bastante funcional para a maioria dos problemas \cite{breiman:rf, lantz:mlinR}.

Existem algumas boas implementações de RF no pacote \textit{caret}. Dentre as mais adequadas, optou-se por utilizar o método \textit{ranger}, o qual se mostrou bastante rápido e eficiente, mesmo lidando com grandes volumes de dados \cite{ranger:rf, caret:r}.

Ao utilizar esta implementação, é possível customizar três parâmetros para melhorar a performance do modelo, sendo: (i) \textit{mtry}, que indica o número de variáveis selecionadas aleatoriamente em cada interação; (ii) \textit{splitrule}, indica o algoritmo utilizado para realizar as divisões de árvore; e (iii) \textit{min.node.size}, que controla a complexidade das árvores, onde valores baixos garantem árvores mais complexas e com vários níveis,  enquanto valores maiores geram árvores com pouca complexidade e divisões menores.

É importante considerar que árvores de alta complexidade aumentam o risco de padrões específicos demais para o conjunto de dados de treino (\textit{overfitting}). Enquanto árvores pouco complexas podem não perceber alguns padrões importantes, deixando o modelo muito flexível (\textit{underfitting}).

Para encontrar o melhor modelo, foram testados diversos conjuntos de parâmetros. Foram utilizadas \textit{2, 4, 8, 16 ou 20} variáveis selecionadas aleatoriamente (\textit{mtry}), combinadas com \textit{\say{gini} e \say{extratrees}} para \textit{splitrule} e o \textit{min.node.size} sendo \textit{1, 3 ou 5}. Percebeu-se, durante o processo, que considerar muitas variáveis para explicar o modelo interfere de forma negativa na performance do mesmo. Dentre as combinações testadas, o melhor modelo foi obtido ao utilizar \textit{mtry = 4}, \textit{splitrule = \say{gini}} e \textit{min.node.size = 3}.

\subsubsection{Support Vector Machine}

\textit{Support Vector Machine (SVM)} é um modelo que tem por objetivo encontrar um hiperplano que classifique distintamente os pontos de dados. Estes hiperplanos são os limites que separam grupos disintos de elementos e, os pontos mais próximos dos limites são chamados de vetores de suporte e são elementos de maior complexidade de classificação. O SVM faz uso destes vetores de suporte para encontrar a melhor divisão possível entre os grupos. Sendo capaz de classificar os registros com base na proximidade com os limites definidos \cite{lantz:mlinR, rodrigues:wildfire}.

Configurar um bom modelo SVM exige a compreensão de uma quantidade considerável de parâmetros. Desta forma, sua otimização possui maior complexidade em relação aos demais modelos citados. Para o propósito desta pesquisa, o SVM foi calibrado utilizando o método \textit{svmPoly} do pacote \textit{caret}. Este método faz uso do \textit{kernel = \say{polynomial}} e aceita três parâmetros de otimização, sendo: (i) \textit{degree}, indicando a flexibilidade dos limites de decisão entre os grupos; (ii) \textit{scale}, relacionado à distribuição dos dados no plano; e (iii) \textit{C}, especifica um custo para definir os vetores de suporte \cite{lantz:mlinR}.

A parametrização do modelo foi realizada de forma a aplicar todas as combinações entre \textit{degree} (1, 2 e 3), \textit{scale} (0.001, 0.010 e 0.100) e \textit{C} (0.25, 0.50 e 1.00), obtendo o modelo mais favorável utilizando \textit{degree = 2}, \textit{scale = 0.1} e \textit{C = 0.25}. 

\section{Resultados}

Esta seção tem por objetivo apresentar os resultados obtidos e considerar a escolha do modelo mais adequado ao objetivo final da pesquisa.

\subsection{Performance dos Modelos}

Conforme apresentado na tabela \ref{tab:performance_modelos}, os modelos RF e DT obtiveram performances bastante consideráveis. O modelo RF apresentou, de acordo com o intervalo de confiança, uma acurácia entre 89.88\% e 91.65\%. O modelo SVM também apresentou performance satisfatória, atingindo uma acurácia média de 81.55\%. Dentre os modelos analisados, o NB apresentou o pior desempenho, não atingindo valores superiores a 71.30\%.

\begin{table}[ht]
\centering
\caption{Performance dos modelos obtidos.}
\label{tab:performance_modelos}
\includegraphics[width=.8\textwidth]{performance_modelos.png}
\end{table}

Ainda em relação a performance dos modelos, é interessante considerar o tempo de obtenção dos resultados ótimos para cada algoritmo. Observa-se, por exemplo, que para obter acurácia média de 90.79\%, o RF demorou pouco mais de 67 minutos (4028 segundos), enquanto que o DT necessitou de 8 minutos (481 segundos) para obter uma performance similar. Dependendo da aplicabilidade do modelo, um pequeno ganho de acurácia pode não justificar o aumento no custo computacional para obtenção do modelo final.

Outro ponto a ser considerado, é a complexidade da parametrização dos modelos SVM. Mesmo com uma configuração básica, o modelo conseguiu resultados expressivos. Um estudo mais aprofundado do funcionamento do algoritmo pode contribuir com um aumento significativo de performance.

Por fim, para esta pesquisa, optou-se por utilizar o modelo de Random Forest na classifcação das interações antrópicas. Sendo assim, seus resultados são aprofundados nas próximas subseções.

\subsection{Importância das Variáveis}

De acordo com os procedimentos do modelo RF, a presença de resíduos sólidos, a causa da principal lesão nos diagnósticos presuntivo e primário e o principal órgão lesionado no diagnóstico presuntivo são os fatores mais importantes para determinar a interação antrópica com o indivíduo (figura \ref{fig:importancia_variaveis}).  

\begin{figure}[ht]
\centering
\includegraphics[width=.8\textwidth]{rf_importancia_variaveis.png}
\caption{Contribuição de variáveis para explicação do modelo RF.}
\label{fig:importancia_variaveis}
\end{figure}

Ao considerar as variáveis individualmente, é possível observar que a presença de resíduos sólidos possui a maior capacidade explicativa para o modelo. Corroborando para o fato de que a presença de resíduos está fortemente associada à algum tipo de interação antrópica. Outro fator bastante determinante é a causa da principal lesão diagnosticada. Além disso, as variáveis indicativas do estado dos órgãos pouco contribuíram para o modelo. Por fim, para a explicação do modelo foram utilizadas as quatro variáveis de maior contribuição.

\subsection{Matriz de confusão}

Antes de verificar a matriz de confusão obtida pelo RF, é importante considerar a capacidade preditiva para cada tipo de interação, conforme tabela \ref{tab:capacidade_preditiva}. É possível perceber, por exemplo, que o modelo oscila bastante em identificar verdadeiros positivos (\textit{Sensitivity}), sendo melhor na classificação de \say{interação com pesca} e \say{interação com resíduo lixo} respectivamente. No entanto, a capacidade de prever verdadeiros negativos (\textit{Specificity}) é bastante alta para todos os tipos de interação.

\begin{table}[ht]
\centering
\caption{Capacidade preditiva para cada classe de interação do modelo RF.}
\label{tab:capacidade_preditiva}
\includegraphics[width=.8\textwidth]{rf_valores_por_variavel.png}
\end{table}

Por fim, conforme a matriz de confusão (figura \ref{fig:matriz_confusao}), o modelo teve bons índices de acerto para a maioria das classes. Destacam-se as classes de \say{interação com pesca} e \say{interação com resíduo lixo} com 1574 e 1930 registros classificados corretamente. 

É possível perceber, também, que para as classes \say{interação com atividade de exploração e produção de petróleo e gás} e \say{interação com óleo} o modelo foi pouco efetivo, classificando a maioria dos registros como outro tipo de interação. Isto pode ter sido influenciado pelo baixo índice de ocorrência destas classes na base de treino, corroborando para os índices de \textit{Sensitivity} apresentados na tabela \ref{tab:capacidade_preditiva}.

\begin{figure}[ht]
\centering
\includegraphics[width=1\textwidth]{rf_matriz_confusao.png}
\caption{Matriz de confusão para o modelo RF.}
\label{fig:matriz_confusao}
\end{figure}

\subsection{Aplicação do Modelo}

Como processo final, utilizou-se o modelo RF obtido para classificar os registros que não apresentam informação de interação antrópica (figura \ref{fig:predicao_final}).

Destaca-se que, dentre os pouco mais de 17 mil registros, o modelo não classificou nenhuma ocorrência como \say{interação com atividade de exploração e produção de petróleo e gás} e apenas uma ocorrência para \say{interação com dragagem} e \say{interação com óleo}. Considerando o baixo índice de sensibilidade do modelo para estas classes, acredita-se que os mesmos tenham sido considerados como \say{interação com pesca} (14065 inferências).

\begin{figure}[ht]
\centering
\includegraphics[width=1\textwidth]{rf_predicao_final.png}
\caption{Predição de interação do registros que não apresentavam interação antrópica.}
\label{fig:predicao_final}
\end{figure}

\section{Conclusão}

Após o processo de análise, limpeza e processamento dos algoritmos de aprendizagem de máquina, foi possível obter modelos com um percentual de acurácia promissores para uma primeira abordagem nos dados de necrópsia do PMP-BS. Tanto o RF quanto DT obtiveram resultados bastante satisfatórios em identificar interações antrópicas nos animais necropsiados. O RF, especificamente, parece ser a escolha mais adequada pois, além da acurácia obtida, utiliza poucas variáveis preditoras e possui uma configuação relativamente simples. 

Ainda sobre o modelo obtido, é importante salientar que o mesmo é mais eficaz em identificar corretamente verdadeiros negativos (especificidade). A capacidade de identificar corretamente verdadeiros positivos (sensibilidade) teve bastante oscilação dependendo da classe em questão, sendo que o modelo foi mais capaz de inferir as classes \say{interação com pesca} e \say{interação com resíduo lixo}.

O processo de compreensão e limpeza dos dados obtidos foi bastante oneroso, consumindo cerca de 80\% de todo o processo da pesquisa. É importante compreender a importância de cada informação e quais os impactos que as variáveis podem causar na obtenção dos modelos. A remoção ou o uso exagerado de variáveis pode deixar o modelo tendencioso, o que impede o mesmo de detectar padrões, impactando negativamente na performance.

Ainda em relação à limpeza dos dados, a qualidade dos registros teve bastante impacto na análise. Diversas variáveis possuíam preenchimento fora do padrão ou nulos, enquanto outras possuíam mais de um tipo de informação. Seria interessante, talvez, uma melhor organização das informações, prevenindo inconsistências nos dados de entrada sem restrição de preenchimento.

Finalizando, apesar dos bons resultados obtidos em uma primeira pesquisa e exploração de possíveis modelos para identificar interações antrópicas em animais coletados nas regiões costeiras, fica clara a possibilidade de continuação e aperfeiçoamento das análises e modelos obtidos.

Uma possível continuação da pesquisa envolve considerar, também, as necrópsias que possuam mais de uma interação antrópica ao mesmo tempo, identificando outros padrões não percebidos nesta pesquisa. Também é possível analisar variáveis textuais para extrair características que possam ser relevantes ao contexto da análise por parte do modelo.

\bibliographystyle{sbc}
\bibliography{referencias}

\end{document}
